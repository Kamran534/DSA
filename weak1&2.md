# Module 1: Foundations and Complexity Analysis

## ğŸ“š Module Overview
**Duration:** Week 1-2 (14 days)  
**Daily Time Commitment:** 2-3 hours  
**Total Practice Problems:** 23 problems

Welcome to your DSA journey! This module lays the foundation for everything you'll learn. Think of it as learning the alphabet before writing stories.

---

# 1.1 Introduction to DSA

## What are Data Structures and Algorithms?

### Simple Analogy
Imagine you're organizing your kitchen:
- **Data Structures** = Different storage containers (jars, drawers, shelves)
- **Algorithms** = Recipes and methods (how to find ingredients, how to cook)

### Formal Definition

**Data Structure:**  
A way to organize, store, and manage data so that it can be accessed and modified efficiently.

**Algorithm:**  
A step-by-step procedure or formula for solving a problem.

### Real-World Example

```
Problem: Store 1000 student records and find a student by ID

Bad Approach (No proper data structure):
- Write all records on random pages
- To find: Check every single page (Very slow!)

Good Approach (Using proper data structure):
- Use a hash table (like a dictionary)
- To find: Look up directly by ID (Very fast!)
```

### Visual Representation

```
DATA STRUCTURES
===============

Array:        [1][2][3][4][5]        â†’ Items in a row
Linked List:  [1]â†’[2]â†’[3]â†’[4]       â†’ Chain of items
Tree:           1                    â†’ Hierarchical
              /   \
             2     3
            / \
           4   5
           
Stack:      |_5_|  â† top             â†’ Last in, first out
            |_4_|
            |_3_|
            |_2_|
            |_1_|
            
Queue:      [1][2][3][4][5]         â†’ First in, first out
            â†‘               â†‘
          front            rear
```

---

## Why DSA Matters in Software Development

### 1. **Efficiency (Speed and Memory)**

**Analogy:** Finding a book in a library
- **Without system:** Check every book one by one (Hours!)
- **With Dewey Decimal System:** Go directly to the right shelf (Minutes!)

**Real Impact:**
```
Searching 1 million records:

Method 1 (Linear Search):
Time: 1 million operations
User experience: ğŸ˜¡ App freezes!

Method 2 (Binary Search):
Time: 20 operations
User experience: ğŸ˜Š Instant results!
```

### 2. **Scalability**

```
Your App Growth:

Day 1:    100 users    â†’ Any code works
Day 30:   10,000 users â†’ Need better algorithms
Day 365:  1,000,000    â†’ DSA becomes critical!

Without DSA:
100 users  â†’ 0.1 seconds response âœ“
1M users   â†’ 16 minutes response âœ— (App crashes!)

With DSA:
100 users  â†’ 0.1 seconds response âœ“
1M users   â†’ 0.5 seconds response âœ“
```

### 3. **Problem-Solving Skills**

DSA trains your brain to:
- Break down complex problems
- Think systematically
- Find optimal solutions
- Debug efficiently

### 4. **Career Opportunities**

```
Tech Interviews:

FAANG Companies (Google, Meta, Amazon, etc.):
â”œâ”€â”€ 70% DSA questions
â”œâ”€â”€ 20% System design
â””â”€â”€ 10% Behavioral

Startups & Product Companies:
â”œâ”€â”€ 50% DSA questions
â”œâ”€â”€ 30% Practical coding
â””â”€â”€ 20% System design
```

---

## Problem-Solving Approaches

### The 4-Step Problem-Solving Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. UNDERSTAND THE PROBLEM                  â”‚
â”‚     â†“                                       â”‚
â”‚  2. PLAN YOUR APPROACH                      â”‚
â”‚     â†“                                       â”‚
â”‚  3. IMPLEMENT THE SOLUTION                  â”‚
â”‚     â†“                                       â”‚
â”‚  4. TEST AND OPTIMIZE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 1: UNDERSTAND THE PROBLEM

**Ask yourself:**
- What is the input?
- What is the expected output?
- What are the constraints?
- What are edge cases?

**Example Problem:**  
"Find the maximum number in an array"

```
Clarifying Questions:
âœ“ What if array is empty? â†’ Return error or null?
âœ“ Can array have negative numbers? â†’ Yes
âœ“ What if all numbers are equal? â†’ Return that number
âœ“ Array size limit? â†’ Up to 10^6 elements

Input:  [3, 7, 2, 9, 1]
Output: 9

Edge Cases:
- Empty array: []
- Single element: [5]
- All same: [4, 4, 4, 4]
- All negative: [-5, -2, -10]
```

### Step 2: PLAN YOUR APPROACH

**Think through different approaches:**

```
Problem: Find maximum in array [3, 7, 2, 9, 1]

Approach 1 (Brute Force):
- For each element, check if it's greater than all others
- Time: O(nÂ²) - Too slow!

Approach 2 (Single Pass):
- Keep track of max seen so far
- Update max when you find larger
- Time: O(n) - Much better!

Approach 3 (Sorting):
- Sort array and take last element
- Time: O(n log n) - Worse than Approach 2
```

**Visualization:**

```
Approach 2 (Best):

Initial: max = first element = 3

[3, 7, 2, 9, 1]
 â†‘
max=3

[3, 7, 2, 9, 1]
    â†‘
max=7 (updated!)

[3, 7, 2, 9, 1]
       â†‘
max=7 (no change)

[3, 7, 2, 9, 1]
          â†‘
max=9 (updated!)

[3, 7, 2, 9, 1]
             â†‘
max=9 (no change)

Result: 9
```

### Step 3: IMPLEMENT THE SOLUTION

**Pseudocode first, then real code:**

```
Pseudocode:
-----------
function findMax(array):
    if array is empty:
        return error
    
    max = array[0]
    
    for each element in array:
        if element > max:
            max = element
    
    return max
```

**Python Implementation:**

```python
def find_max(arr):
    # Handle edge case
    if not arr:
        return None
    
    # Initialize max with first element
    max_value = arr[0]
    
    # Iterate through array
    for num in arr:
        if num > max_value:
            max_value = num
    
    return max_value

# Test
print(find_max([3, 7, 2, 9, 1]))  # Output: 9
```

### Step 4: TEST AND OPTIMIZE

**Test Cases:**

```
Test 1 (Normal case):
Input:  [3, 7, 2, 9, 1]
Output: 9 âœ“

Test 2 (Edge case - empty):
Input:  []
Output: None âœ“

Test 3 (Edge case - single):
Input:  [5]
Output: 5 âœ“

Test 4 (Edge case - negatives):
Input:  [-5, -2, -10]
Output: -2 âœ“

Test 5 (Edge case - duplicates):
Input:  [4, 4, 4, 4]
Output: 4 âœ“
```

**Optimization Check:**
- Time Complexity: O(n) - Can't do better than looking at each element once âœ“
- Space Complexity: O(1) - Only using one variable âœ“
- Code is readable and maintainable âœ“

---

## Common Problem-Solving Patterns

### Pattern 1: Two Pointers

**When to use:** Working with sorted arrays or need to find pairs

```
Problem: Find if pair exists with sum = target

Array: [1, 2, 3, 4, 5, 6]
Target: 9

Visualization:
[1, 2, 3, 4, 5, 6]
 â†‘           â†‘
left        right

1 + 6 = 7 < 9 â†’ Move left pointer right
[1, 2, 3, 4, 5, 6]
    â†‘        â†‘
   left     right

2 + 6 = 8 < 9 â†’ Move left pointer right
[1, 2, 3, 4, 5, 6]
       â†‘     â†‘
      left  right

3 + 6 = 9 âœ“ Found!
```

### Pattern 2: Sliding Window

**When to use:** Contiguous subarray/substring problems

```
Problem: Find maximum sum of k consecutive elements

Array: [2, 1, 5, 1, 3, 2], k = 3

Window slides:
[2, 1, 5], 1, 3, 2  â†’ sum = 8
 â””â”€â”€â”€â”€â”€â”˜

 2, [1, 5, 1], 3, 2 â†’ sum = 7
    â””â”€â”€â”€â”€â”€â”˜

 2, 1, [5, 1, 3], 2 â†’ sum = 9 âœ“ (maximum)
       â””â”€â”€â”€â”€â”€â”˜

 2, 1, 5, [1, 3, 2] â†’ sum = 6
          â””â”€â”€â”€â”€â”€â”˜
```

### Pattern 3: Divide and Conquer

**When to use:** Can break problem into smaller similar subproblems

```
Problem: Find maximum in array [3, 7, 2, 9, 1, 8, 4]

Divide:
                [3, 7, 2, 9, 1, 8, 4]
                /                   \
          [3, 7, 2]              [9, 1, 8, 4]
          /      \                /         \
      [3, 7]    [2]           [9, 1]      [8, 4]
      /   \                   /   \        /   \
    [3]   [7]               [9]  [1]     [8]  [4]

Conquer (merge back up):
    [3]   [7] â†’ max = 7
      \   /
      [3, 7] â†’ max = 7    [2] â†’ max = 2
           \              /
            [3, 7, 2] â†’ max = 7

    [9]   [1] â†’ max = 9     [8]   [4] â†’ max = 8
      \   /                   \   /
      [9, 1] â†’ max = 9        [8, 4] â†’ max = 8
           \                  /
            [9, 1, 8, 4] â†’ max = 9
                    \           /
                  [3, 7, 2, 9, 1, 8, 4] â†’ max = 9
```

---

## ğŸ¯ Practice: 5 Basic Problem-Solving Exercises

### Problem 1: Sum of Array Elements
**Difficulty:** Easy  
**Topics:** Arrays, Basic iteration

```
Input:  [1, 2, 3, 4, 5]
Output: 15

Hint: Use a variable to accumulate sum
```

### Problem 2: Count Even Numbers
**Difficulty:** Easy  
**Topics:** Arrays, Conditionals

```
Input:  [1, 2, 3, 4, 5, 6]
Output: 3 (numbers: 2, 4, 6)

Hint: Use modulo operator (%) to check if even
```

### Problem 3: Reverse an Array
**Difficulty:** Easy  
**Topics:** Arrays, Two pointers

```
Input:  [1, 2, 3, 4, 5]
Output: [5, 4, 3, 2, 1]

Hint: Swap elements from both ends moving towards center
```

### Problem 4: Find Second Largest
**Difficulty:** Medium  
**Topics:** Arrays, Logic

```
Input:  [3, 7, 2, 9, 1, 8]
Output: 8

Hint: Keep track of both largest and second largest
```

### Problem 5: Check if Sorted
**Difficulty:** Easy  
**Topics:** Arrays, Comparison

```
Input:  [1, 2, 3, 4, 5]
Output: True

Input:  [1, 3, 2, 4]
Output: False

Hint: Compare each element with the next one
```

---

# 1.2 Time and Space Complexity

## Why Learn Complexity Analysis?

**Analogy:** Choosing transportation

```
Traveling 100km:

Walking:    20 hours    â†’ O(nÂ²) algorithm
Bicycle:    5 hours     â†’ O(n log n) algorithm
Car:        1 hour      â†’ O(n) algorithm
Airplane:   15 minutes  â†’ O(log n) algorithm

For short distance (10km), walking is fine.
For long distance (1000km), you NEED airplane!

Similarly:
- Small data (n=100): Any algorithm works
- Large data (n=1M): Algorithm choice is critical!
```

---

## Big O Notation (O, Î©, Î˜)

### Understanding Big O

**Big O** = Upper bound = Worst case scenario = "At most this slow"

**Analogy:** Driving to work
- Big O = "It will take AT MOST 1 hour" (accounting for traffic)
- You're telling your boss the WORST case time

### Formal Definition

```
An algorithm is O(f(n)) if:
- As input size n grows
- Running time grows no faster than f(n)
- Ignoring constant factors and lower-order terms
```

### The Three Notations

```
Big O (O)    â†’ Upper bound    â†’ Worst case
Big Omega (Î©) â†’ Lower bound    â†’ Best case
Big Theta (Î˜) â†’ Tight bound    â†’ Average case

Example: Linear Search in array

Best case (Î©):    Element is first  â†’ Î©(1)
Average case (Î˜): Element in middle â†’ Î˜(n)
Worst case (O):   Element is last   â†’ O(n)
```

### Visual Representation

```
Running Time
    â†‘
    |                                    â•± f(n) = nÂ²
    |                                 â•±
    |                              â•±
    |                Big O boundary
    |         â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    |      â•±  Actual algorithm time
    |   â•±
    |â•±
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Input size (n)
    
The actual time never exceeds the Big O boundary
```

---

## Best, Average, and Worst Case Analysis

### Linear Search Example

```python
def linear_search(arr, target):
    for i in range(len(arr)):
        if arr[i] == target:
            return i
    return -1
```

**Scenario Analysis:**

```
Array: [5, 2, 8, 1, 9, 3]
Target: ?

Case 1: BEST CASE (Î©)
Target = 5 (first element)
[5, 2, 8, 1, 9, 3]
 â†‘ Found immediately!
Comparisons: 1
Time: Î©(1)

Case 2: AVERAGE CASE (Î˜)
Target = 1 (middle-ish)
[5, 2, 8, 1, 9, 3]
 âœ—  âœ—  âœ—  âœ“
Comparisons: 4 (on average n/2)
Time: Î˜(n)

Case 3: WORST CASE (O)
Target = 7 (not in array)
[5, 2, 8, 1, 9, 3]
 âœ—  âœ—  âœ—  âœ—  âœ—  âœ—  All checked!
Comparisons: 6 (all n elements)
Time: O(n)
```

### Why We Focus on Worst Case (Big O)

```
Real-world analogy:

Building a bridge:
âŒ "It can hold 100 cars on average"
âœ“ "It can hold 100 cars in worst conditions"

Writing algorithms:
âŒ "It runs fast usually"
âœ“ "It runs within time limit always"
```

---

## Common Time Complexities

### The Complexity Hierarchy

```
Faster â†‘
       |
O(1)   |  Constant      â†’ Best!
O(log n)|  Logarithmic   â†’ Excellent
O(n)   |  Linear        â†’ Good
O(n log n) Linearithmic  â†’ Acceptable
O(nÂ²)  |  Quadratic     â†’ Slow
O(nÂ³)  |  Cubic         â†’ Very slow
O(2â¿)  |  Exponential   â†’ Extremely slow
O(n!)  |  Factorial     â†’ Practically unusable
       |
Slower â†“
```

### Visual Growth Comparison

```
Input Size (n) â†’     10      100     1,000    10,000

O(1)                 1       1       1        1
O(log n)             3       7       10       13
O(n)                 10      100     1,000    10,000
O(n log n)           30      700     10,000   130,000
O(nÂ²)                100     10,000  1M       100M
O(2â¿)                1,024   âˆ       âˆ        âˆ
O(n!)                3.6M    âˆ       âˆ        âˆ

âˆ = Takes too long to complete
```

### Real-World Time Comparison

```
If O(1) takes 1 second:

n = 1,000:
O(1):      1 second       âœ“ Instant
O(log n):  10 seconds     âœ“ Very fast
O(n):      16 minutes     âœ“ Acceptable
O(n log n): 2.7 hours     ~ Slow
O(nÂ²):     31 years       âœ— Unusable
O(2â¿):     10Â²â¹Â³ years    âœ— Never finishes
```

---

## Detailed Complexity Examples

### 1. O(1) - Constant Time

**Definition:** Takes same time regardless of input size

**Examples:**
```python
# Example 1: Array access
def get_first_element(arr):
    return arr[0]  # Always one operation
    
# Example 2: Math operation
def add_numbers(a, b):
    return a + b   # Always one operation

# Example 3: Hash table lookup
def find_in_dict(dictionary, key):
    return dictionary[key]  # Always one operation (average)
```

**Visualization:**
```
Time
  â†‘
  |  â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬ (flat line)
  |
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Input size
  
No matter how large input is, time stays constant!
```

**Real-world analogy:** Checking your watch
- Takes same time whether you own 1 watch or 1000 watches

---

### 2. O(log n) - Logarithmic Time

**Definition:** Reduces problem size by half each step

**The Binary Search Magic:**
```
Finding 67 in sorted array: [1, 5, 12, 23, 34, 45, 56, 67, 78, 89, 90]

Step 1: Check middle (45)
        [1, 5, 12, 23, 34, 45, 56, 67, 78, 89, 90]
                           â†‘
        67 > 45, search right half
        
Step 2: Check middle of right half (78)
        [56, 67, 78, 89, 90]
              â†‘
        67 < 78, search left half
        
Step 3: Check middle of left half (67)
        [56, 67]
             â†‘
        Found! âœ“

Elements: 11
Steps: 3 (logâ‚‚ 11 â‰ˆ 3.46)
```

**Why it's powerful:**
```
Array size      Steps needed
1               0
10              3-4
100             6-7
1,000           9-10
1,000,000       19-20 (Amazing!)
1,000,000,000   29-30 (Still fast!)
```

**Real-world analogy:** Phonebook search
- 1 million names
- Open to middle, decide if name is before or after
- Repeat with half
- Find in ~20 steps!

---

### 3. O(n) - Linear Time

**Definition:** Time grows proportionally with input size

**Examples:**
```python
# Example 1: Finding maximum
def find_max(arr):
    max_val = arr[0]
    for num in arr:           # Check each element once
        if num > max_val:
            max_val = num
    return max_val

# Example 2: Counting occurrences
def count_target(arr, target):
    count = 0
    for num in arr:           # Check each element once
        if num == target:
            count += 1
    return count
```

**Visualization:**
```
Time
  â†‘                        â•±
  |                      â•±
  |                    â•±
  |                  â•±
  |                â•±
  |              â•±
  |            â•±
  |          â•±
  |        â•±
  |      â•±
  |    â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Input size

Double input = Double time
```

**Real-world analogy:** Reading a book
- 100 pages = X hours
- 200 pages = 2X hours
- 300 pages = 3X hours

---

### 4. O(n log n) - Linearithmic Time

**Definition:** Combines linear and logarithmic complexity

**Examples:**
```python
# Merge Sort (most efficient sorting algorithms)
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])    # log n divisions
    right = merge_sort(arr[mid:])   
    
    return merge(left, right)        # n merging operations

# Total: O(n log n)
```

**Visualization:**
```
        [8, 3, 5, 4, 7, 6, 1, 2]        Level 0: n elements
           /                  \
    [8, 3, 5, 4]         [7, 6, 1, 2]   Level 1: n elements
      /        \           /        \
  [8, 3]    [5, 4]     [7, 6]    [1, 2] Level 2: n elements
   / \       / \        / \       / \
 [8] [3]   [5] [4]    [7] [6]   [1] [2] Level 3: n elements

Total levels: log n
Work per level: n
Total: O(n log n)
```

**Real-world analogy:** Tournament organization
- n players need log n rounds
- Each round everyone plays (n games)

---

### 5. O(nÂ²) - Quadratic Time

**Definition:** Nested loops over input

**Examples:**
```python
# Example 1: Bubble Sort
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):           # Outer loop: n times
        for j in range(n-1):     # Inner loop: n times
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]

# Example 2: Finding all pairs
def print_all_pairs(arr):
    for i in range(len(arr)):    # Outer loop: n times
        for j in range(len(arr)): # Inner loop: n times
            print(arr[i], arr[j])
```

**Visualization:**
```
Array: [1, 2, 3, 4]

Pairs checked:
(1,1) (1,2) (1,3) (1,4)  â†’ 4 comparisons
(2,1) (2,2) (2,3) (2,4)  â†’ 4 comparisons
(3,1) (3,2) (3,3) (3,4)  â†’ 4 comparisons
(4,1) (4,2) (4,3) (4,4)  â†’ 4 comparisons

Total: 4 Ã— 4 = 16 = nÂ²
```

**Growth visualization:**
```
Time
  â†‘                           â•±
  |                         â•±
  |                       â•±
  |                    â•±
  |                 â•±
  |              â•±
  |           â•±
  |        â•±
  |     â•±
  |  â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Input size

Growth accelerates quickly!
```

**Real-world analogy:** Handshakes at party
- 10 people = 45 handshakes
- 100 people = 4,950 handshakes
- 1,000 people = 499,500 handshakes!

---

### 6. O(2â¿) - Exponential Time

**Definition:** Doubles with each additional input

**Example: Fibonacci (naive recursive)**
```python
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
```

**Visualization of recursion tree:**
```
                    fib(5)
                   /      \
              fib(4)        fib(3)
             /     \        /     \
        fib(3)   fib(2)  fib(2)  fib(1)
        /   \     /  \    /  \
    fib(2) fib(1) ...  ... ...  ...
     / \
 fib(1) fib(0)

Notice: Many calculations repeated!
fib(3) calculated 2 times
fib(2) calculated 3 times
Gets exponentially worse!
```

**Growth rate:**
```
n    Operations
1    2
2    4
3    8
5    32
10   1,024
20   1,048,576
30   1,073,741,824 (over a billion!)
```

**Real-world analogy:** Chain emails
- You send to 2 people
- Each sends to 2 people
- After 20 levels = 1 million emails!

---

### 7. O(n!) - Factorial Time

**Definition:** Worse than exponential

**Example: Generating all permutations**
```python
def permutations(arr):
    if len(arr) <= 1:
        return [arr]
    result = []
    for i in range(len(arr)):
        rest = arr[:i] + arr[i+1:]
        for p in permutations(rest):
            result.append([arr[i]] + p)
    return result

# For array [1,2,3,4,5]
# 5! = 120 permutations
```

**Growth rate:**
```
n     n!
1     1
2     2
3     6
4     24
5     120
10    3,628,800
15    1,307,674,368,000
20    2.43 Ã— 10Â¹â¸ (Practically impossible!)
```

**Real-world analogy:** Arranging people in line
- 3 people = 6 ways
- 10 people = 3.6 million ways
- 20 people = More than atoms in observable universe!

---

## How to Calculate Time Complexity

### Rule 1: Count Operations

```python
def example1(n):
    x = 5           # 1 operation
    y = 10          # 1 operation
    z = x + y       # 1 operation
    return z        # 1 operation

# Total: 4 operations (constant)
# Complexity: O(1)
```

### Rule 2: Drop Constants

```python
def example2(n):
    for i in range(n):      # n operations
        print(i)
    
    for i in range(n):      # n operations
        print(i)
    
    for i in range(n):      # n operations
        print(i)

# Total: 3n operations
# We drop the constant: O(3n) â†’ O(n)
```

### Rule 3: Different Terms for Different Inputs

```python
def example3(arr1, arr2):
    for x in arr1:         # m operations
        print(x)
    
    for y in arr2:         # n operations
        print(y)

# Total: m + n operations
# Complexity: O(m + n)  (NOT O(n))
```

### Rule 4: Drop Non-Dominant Terms

```python
def example4(n):
    # Part 1: Nested loops
    for i in range(n):
        for j in range(n):
            print(i, j)     # nÂ² operations
    
    # Part 2: Single loop
    for i in range(n):
        print(i)            # n operations

# Total: nÂ² + n
# Drop non-dominant: O(nÂ² + n) â†’ O(nÂ²)
```

**Why drop smaller terms?**
```
When n = 1,000:
nÂ² = 1,000,000
n  = 1,000
nÂ² + n = 1,001,000 â‰ˆ nÂ² (difference is negligible)
```

### Rule 5: Nested Loops Multiply

```python
def example5(n):
    for i in range(n):           # Outer: n times
        for j in range(n):       # Inner: n times (for each i)
            for k in range(n):   # Innermost: n times (for each j)
                print(i, j, k)

# Total: n Ã— n Ã— n = nÂ³
# Complexity: O(nÂ³)
```

---

## Complexity Analysis Examples

### Example 1: Simple Loop
```python
def sum_array(arr):
    total = 0                # O(1)
    for num in arr:          # O(n)
        total += num         # O(1) Ã— n times
    return total             # O(1)

# Analysis:
# - Loop runs n times
# - Each operation inside is O(1)
# - Total: O(n)
```

### Example 2: Nested Loops
```python
def print_pairs(arr):
    for i in range(len(arr)):        # n times
        for j in range(len(arr)):    # n times for each i
            print(arr[i], arr[j])    # O(1)

# Analysis:
# - Outer loop: n times
# - Inner loop: n times per outer iteration
# - Total: n Ã— n = O(nÂ²)
```

### Example 3: Two Separate Loops
```python
def process_arrays(arr1, arr2):
    # First loop
    for x in arr1:              # m times
        print(x)
    
    # Second loop
    for y in arr2:              # n times
        print(y)

# Analysis:
# - First loop: O(m)
# - Second loop: O(n)
# - Total: O(m + n)
```

### Example 4: Dependent Nested Loops
```python
def print_triangle(n):
    for i in range(n):              # n times
        for j in range(i):          # i times (0, 1, 2, ..., n-1)
            print("*")

# Analysis:
# Iterations: 0 + 1 + 2 + ... + (n-1) = n(n-1)/2
# Total: O(nÂ²/2) â†’ O(nÂ²)
```

### Example 5: Logarithmic Loop
```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    
    while left <= right:
        mid = (left + right) // 2
        
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1       # Halves search space
        else:
            right = mid - 1      # Halves search space
    
    return -1

# Analysis:
# Each iteration halves the search space
# n â†’ n/2 â†’ n/4 â†’ n/8 â†’ ... â†’ 1
# Total: O(log n)
```

### Example 6: Multiple Different Complexities
```python
def complex_function(arr):
    # Part 1: O(n)
    max_val = max(arr)
    
    # Part 2: O(nÂ²)
    for i in range(len(arr)):
        for j in range(len(arr)):
            if arr[i] + arr[j] == max_val:
                print(i, j)
    
    # Part 3: O(n log n)
    sorted_arr = sorted(arr)
    
    return sorted_arr

# Analysis:
# O(n) + O(nÂ²) + O(n log n)
# Drop non-dominant: O(nÂ²)
```

---

## Space Complexity Analysis

### What is Space Complexity?

**Space Complexity** = Extra memory used by algorithm (excluding input)

**Analogy:** Cooking in kitchen
- **Time Complexity** = How long it takes to cook
- **Space Complexity** = How many pots/pans you use

### Components of Space

```
Total Space = Input Space + Auxiliary Space

Input Space: Memory for input data (we don't count this)
Auxiliary Space: Extra memory algorithm uses (we count this)
```

### Space Complexity Examples

#### Example 1: O(1) - Constant Space
```python
def find_max(arr):
    max_val = arr[0]        # 1 variable
    
    for num in arr:
        if num > max_val:
            max_val = num   # Reusing same variable
    
    return max_val

# Extra memory: Only max_val (one variable)
# Space Complexity: O(1)
```

**Visualization:**
```
Memory:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ max_val  â”‚  â† Only one extra variable
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

No matter how large input array is!
```

#### Example 2: O(n) - Linear Space
```python
def reverse_array(arr):
    reversed_arr = []           # New array
    
    for i in range(len(arr)-1, -1, -1):
        reversed_arr.append(arr[i])
    
    return reversed_arr

# Extra memory: New array of size n
# Space Complexity: O(n)
```

**Visualization:**
```
Memory:
Original:  [1, 2, 3, 4, 5]  â† Input (doesn't count)
           â†“ â†“ â†“ â†“ â†“
Reversed:  [5, 4, 3, 2, 1]  â† New array (counts!)

Extra space = n elements = O(n)
```

#### Example 3: O(n) - Recursive Call Stack
```python
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n-1)

# Each call adds to call stack
# Space Complexity: O(n)
```

**Visualization:**
```
Call Stack for factorial(5):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ factorial(5)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ factorial(4)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ factorial(3)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ factorial(2)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ factorial(1)  â”‚  â† Max depth = n
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Space: O(n) for call stack
```

#### Example 4: O(nÂ²) - 2D Array
```python
def create_matrix(n):
    matrix = []
    for i in range(n):
        row = []
        for j in range(n):
            row.append(i * j)
        matrix.append(row)
    return matrix

# Extra memory: n Ã— n matrix
# Space Complexity: O(nÂ²)
```

**Visualization:**
```
For n = 4:

matrix = [
    [0, 0, 0, 0],    â† 4 elements
    [0, 1, 2, 3],    â† 4 elements
    [0, 2, 4, 6],    â† 4 elements
    [0, 3, 6, 9]     â† 4 elements
]

Total: 16 = 4Â² = O(nÂ²)
```

### Space-Time Tradeoff

Often we can trade space for time:

```python
# Version 1: Less space, more time
def fibonacci_recursive(n):
    if n <= 1:
        return n
    return fibonacci_recursive(n-1) + fibonacci_recursive(n-2)

# Time: O(2â¿) - Very slow!
# Space: O(n) - Call stack depth

# Version 2: More space, less time
def fibonacci_memoization(n, memo={}):
    if n in memo:
        return memo[n]
    if n <= 1:
        return n
    
    memo[n] = fibonacci_memoization(n-1, memo) + \
              fibonacci_memoization(n-2, memo)
    return memo[n]

# Time: O(n) - Much faster!
# Space: O(n) - Dictionary to store results

# Version 3: Optimal space
def fibonacci_iterative(n):
    if n <= 1:
        return n
    prev, curr = 0, 1
    for _ in range(2, n+1):
        prev, curr = curr, prev + curr
    return curr

# Time: O(n)
# Space: O(1) - Only two variables!
```

---

## Amortized Analysis Basics

### What is Amortized Analysis?

**Definition:** Average time per operation over a sequence of operations

**Analogy:** Gym membership
- Pay $120 annually
- Go 12 times a year
- Amortized cost per visit: $120/12 = $10/visit

Even if some visits are "expensive" (far drive, forgot clothes), average stays same.

### Dynamic Array Example

```
Dynamic Array (like Python list):
- Starts with capacity 4
- When full, doubles capacity
- Copies all elements to new array

Operations:
append(1): [1, _, _, _]           Cost: 1
append(2): [1, 2, _, _]           Cost: 1
append(3): [1, 2, 3, _]           Cost: 1
append(4): [1, 2, 3, 4]           Cost: 1

append(5): Need to resize!
           1. Create new array (size 8)
           2. Copy 4 elements
           3. Add new element
           [1, 2, 3, 4, 5, _, _, _]
           Cost: 5 (4 copies + 1 insert)

append(6): [1, 2, 3, 4, 5, 6, _, _] Cost: 1
append(7): [1, 2, 3, 4, 5, 6, 7, _] Cost: 1
append(8): [1, 2, 3, 4, 5, 6, 7, 8] Cost: 1

append(9): Need to resize!
           Cost: 9 (8 copies + 1 insert)
```

**Analysis:**
```
Total operations: 9 inserts
Costs: 1 + 1 + 1 + 1 + 5 + 1 + 1 + 1 + 9 = 21

Amortized cost per operation: 21/9 â‰ˆ 2.33

Therefore: O(1) amortized time
(Even though some operations take O(n))
```

### Why Amortized Analysis Matters

```
Real-world example:

Bad thinking:
"Resize costs O(n), so append is O(n)" âŒ

Good thinking:
"Most appends cost O(1), rare resizes cost O(n)
 Amortized over many operations: O(1)" âœ“
```

---

## ğŸ¯ Practice: 10 Complexity Analysis Problems

### Problem 1: Single Loop
```python
def mystery1(n):
    count = 0
    for i in range(n):
        count += 1
    return count
```
**Question:** What is time complexity?  
**Answer:** O(n)  
**Explanation:** Loop runs n times, each iteration is O(1)

---

### Problem 2: Nested Loop with Different Ranges
```python
def mystery2(n, m):
    count = 0
    for i in range(n):
        for j in range(m):
            count += 1
    return count
```
**Question:** What is time complexity?  
**Answer:** O(n Ã— m)  
**Explanation:** Outer loop n times, inner loop m times for each

---

### Problem 3: Halving Loop
```python
def mystery3(n):
    count = 0
    i = n
    while i > 1:
        count += 1
        i = i // 2
    return count
```
**Question:** What is time complexity?  
**Answer:** O(log n)  
**Explanation:** i is halved each iteration: n â†’ n/2 â†’ n/4 â†’ ... â†’ 1

---

### Problem 4: Two Separate Loops
```python
def mystery4(arr):
    # Loop 1
    for i in range(len(arr)):
        print(arr[i])
    
    # Loop 2
    for i in range(len(arr)):
        for j in range(len(arr)):
            print(arr[i] + arr[j])
    
    return True
```
**Question:** What is time complexity?  
**Answer:** O(nÂ²)  
**Explanation:** O(n) + O(nÂ²) â†’ Drop smaller term â†’ O(nÂ²)

---

### Problem 5: Dependent Nested Loops
```python
def mystery5(n):
    count = 0
    for i in range(n):
        for j in range(i, n):
            count += 1
    return count
```
**Question:** What is time complexity?  
**Answer:** O(nÂ²)  
**Explanation:**  
Inner loop runs: n + (n-1) + (n-2) + ... + 1 = n(n+1)/2 â‰ˆ nÂ²/2 â†’ O(nÂ²)

---

### Problem 6: Recursive Function
```python
def mystery6(n):
    if n <= 1:
        return 1
    return mystery6(n-1) + mystery6(n-1)
```
**Question:** What is time complexity?  
**Answer:** O(2â¿)  
**Explanation:** Two recursive calls per level, tree doubles each level

---

### Problem 7: Space Complexity
```python
def mystery7(n):
    arr = []
    for i in range(n):
        arr.append(i * 2)
    return arr
```
**Question:** What is space complexity?  
**Answer:** O(n)  
**Explanation:** Creating array of size n

---

### Problem 8: Logarithmic with Work
```python
def mystery8(arr):
    n = len(arr)
    while n > 1:
        for i in range(n):
            print(arr[i])
        n = n // 2
```
**Question:** What is time complexity?  
**Answer:** O(n)  
**Explanation:**  
Work done: n + n/2 + n/4 + ... â‰ˆ 2n â†’ O(n)

---

### Problem 9: Matrix Operations
```python
def mystery9(matrix):
    n = len(matrix)
    total = 0
    for i in range(n):
        for j in range(n):
            total += matrix[i][j]
    return total
```
**Question:** Time and space complexity?  
**Answer:** Time: O(nÂ²), Space: O(1)  
**Explanation:**  
- Time: Nested loops over nÃ—n matrix
- Space: Only using one variable (total)

---

### Problem 10: Tricky Recursion
```python
def mystery10(n):
    if n <= 0:
        return 1
    return mystery10(n-1) + mystery10(n-5)
```
**Question:** What is time complexity?  
**Answer:** O(2^(n/5))  
**Explanation:** Two branches, but n decreases faster than standard binary recursion

---

# 1.3 Mathematical Foundations

## Why Mathematics for DSA?

**Analogy:** Math is to DSA as grammar is to writing
- You can speak without perfect grammar
- But good grammar makes you clearer and more effective
- Similarly, math makes you a better algorithm designer

---

## Logarithms and Exponents

### Understanding Exponents

**Definition:** aâ¿ = a Ã— a Ã— a Ã— ... (n times)

```
2Â¹ = 2
2Â² = 2 Ã— 2 = 4
2Â³ = 2 Ã— 2 Ã— 2 = 8
2â´ = 2 Ã— 2 Ã— 2 Ã— 2 = 16
2âµ = 32
2Â¹â° = 1,024
2Â²â° = 1,048,576
```

**Key Properties:**
```
aáµ Ã— aâ¿ = aáµâºâ¿
Example: 2Â³ Ã— 2Â² = 2Â³âºÂ² = 2âµ = 32

(aáµ)â¿ = aáµË£â¿
Example: (2Â³)Â² = 2Â³Ë£Â² = 2â¶ = 64

aáµ / aâ¿ = aáµâ»â¿
Example: 2âµ / 2Â² = 2âµâ»Â² = 2Â³ = 8
```

### Understanding Logarithms

**Definition:** log_b(x) = "What power do I raise b to get x?"

```
logâ‚‚(8) = 3     because 2Â³ = 8
logâ‚‚(16) = 4    because 2â´ = 16
logâ‚â‚€(100) = 2  because 10Â² = 100
logâ‚â‚€(1000) = 3 because 10Â³ = 1000
```

**Analogy:** Logarithm is "undo" for exponent
```
Exponent:  2 â†’ (square) â†’ 4 â†’ (square) â†’ 16
Logarithm: 2 â† (logâ‚‚)   â† 4 â† (logâ‚‚)   â† 16

If 2â´ = 16, then logâ‚‚(16) = 4
```

### Why Logarithms in DSA?

**1. Halving problems (Binary Search)**
```
Array size: 1,000,000
Steps needed: logâ‚‚(1,000,000) â‰ˆ 20

Why? Each step halves the problem:
1,000,000 â†’ 500,000 â†’ 250,000 â†’ ... â†’ 1
```

**2. Doubling growth (Dynamic Arrays)**
```
Array resizing: 1 â†’ 2 â†’ 4 â†’ 8 â†’ 16 â†’ 32 â†’ ... â†’ n
Number of resizes: logâ‚‚(n)
```

**3. Tree heights**
```
Binary tree with n nodes:
Minimum height: logâ‚‚(n)  (perfectly balanced)
Maximum height: n        (completely skewed)
```

### Important Logarithm Properties

```
1. log(a Ã— b) = log(a) + log(b)
   Example: log(8) = log(4 Ã— 2) = log(4) + log(2)

2. log(a / b) = log(a) - log(b)
   Example: log(8/2) = log(8) - log(2)

3. log(aâ¿) = n Ã— log(a)
   Example: log(8Â²) = 2 Ã— log(8)

4. log_b(a) = log_c(a) / log_c(b)  (base change)
   Example: logâ‚‚(8) = logâ‚â‚€(8) / logâ‚â‚€(2)
```

### Common Logarithms in Programming

```
logâ‚‚(n)  â†’ Binary operations (most common in DSA)
logâ‚â‚€(n) â†’ Decimal operations (counting digits)
ln(n)    â†’ Natural log (advanced algorithms)

In Big O, base doesn't matter:
O(logâ‚‚ n) = O(logâ‚â‚€ n) = O(log n)

Why? They differ by a constant factor
```

---

## Summations and Series

### Arithmetic Series

**Pattern:** 1 + 2 + 3 + ... + n

```
Visual representation:
n = 5

  *
  * *
  * * *
  * * * *
  * * * * *

Total = 1 + 2 + 3 + 4 + 5 = 15
```

**Formula:** Sum = n(n+1)/2

**Derivation (the Gauss trick):**
```
S = 1 + 2 + 3 + ... + n
S = n + (n-1) + (n-2) + ... + 1

Add them:
2S = (n+1) + (n+1) + (n+1) + ... + (n+1)  [n times]
2S = n(n+1)
S = n(n+1)/2
```

**Examples:**
```
1 + 2 + 3 + ... + 100 = 100(101)/2 = 5,050
1 + 2 + 3 + ... + 1000 = 1000(1001)/2 = 500,500
```

**DSA Application:**
```python
def print_pairs(n):
    for i in range(n):
        for j in range(i):  # j goes from 0 to i-1
            print(i, j)

# Inner loop runs: 0 + 1 + 2 + ... + (n-1)
# = (n-1)n/2 â‰ˆ nÂ²/2 â†’ O(nÂ²)
```

### Geometric Series

**Pattern:** 1 + 2 + 4 + 8 + 16 + ... (powers of 2)

```
General form: 1 + r + rÂ² + rÂ³ + ... + râ¿

For r = 2:
1 + 2 + 4 + 8 + ... + 2â¿ = 2^(n+1) - 1
```

**Visual representation:**
```
Level 0:  â—                         = 1
Level 1:  â— â—                       = 2
Level 2:  â— â— â— â—                   = 4
Level 3:  â— â— â— â— â— â— â— â—           = 8

Total = 1 + 2 + 4 + 8 = 15 = 2â´ - 1
```

**DSA Application (Binary Tree):**
```
Complete binary tree:
Level 0: 1 node
Level 1: 2 nodes
Level 2: 4 nodes
...
Level h: 2Ê° nodes

Total nodes = 1 + 2 + 4 + ... + 2Ê° = 2^(h+1) - 1
```

### Harmonic Series

**Pattern:** 1 + 1/2 + 1/3 + 1/4 + ... + 1/n

```
1 + 1/2 + 1/3 + 1/4 + 1/5 + ... + 1/n â‰ˆ ln(n)

For large n:
Î£(1/i) from i=1 to n â‰ˆ ln(n) + 0.577...
```

**DSA Application (Quick Select Average Case):**
```python
# Average number of comparisons
# T(n) = n + n/2 + n/4 + ...
# = n(1 + 1/2 + 1/4 + ...)
# â‰ˆ 2n = O(n)
```

---

## Recurrence Relations

### What are Recurrence Relations?

**Definition:** An equation that defines a sequence based on previous terms

**Analogy:** Recipe that references itself
- "To make big cake, make two smaller cakes and combine"
- Smaller cakes are made the same way

### Common Recurrence Patterns

#### 1. Linear Recurrence
```
T(n) = T(n-1) + c

Example: Simple loop
T(n) = T(n-1) + 1
T(1) = 1

Expansion:
T(n) = T(n-1) + 1
     = T(n-2) + 1 + 1
     = T(n-3) + 1 + 1 + 1
     = ...
     = T(1) + (n-1)
     = 1 + (n-1) = n

Solution: O(n)
```

#### 2. Divide and Conquer (Halving)
```
T(n) = T(n/2) + c

Example: Binary Search
T(n) = T(n/2) + 1
T(1) = 1

Expansion:
T(n) = T(n/2) + 1
     = T(n/4) + 1 + 1
     = T(n/8) + 1 + 1 + 1
     = ...
     = T(1) + logâ‚‚(n)

Solution: O(log n)
```

#### 3. Divide and Conquer (Both Halves)
```
T(n) = 2T(n/2) + n

Example: Merge Sort
T(n) = 2T(n/2) + n
T(1) = 1

Using Master Theorem:
Solution: O(n log n)
```

### Solving Recurrences - Substitution Method

**Example: T(n) = T(n-1) + n**

```
T(n) = T(n-1) + n
     = [T(n-2) + (n-1)] + n
     = T(n-2) + (n-1) + n
     = [T(n-3) + (n-2)] + (n-1) + n
     = T(n-3) + (n-2) + (n-1) + n
     = ...
     = T(1) + 2 + 3 + ... + (n-1) + n
     = 1 + [2 + 3 + ... + n]
     = 1 + n(n+1)/2 - 1
     = n(n+1)/2

Solution: O(nÂ²)
```

### Master Theorem (Quick Reference)

```
For recurrence: T(n) = aT(n/b) + f(n)

Where:
- a = number of subproblems
- n/b = size of each subproblem
- f(n) = cost of divide/combine

Three cases:

Case 1: If f(n) = O(n^c) where c < log_b(a)
        Then T(n) = O(n^(log_b a))

Case 2: If f(n) = O(n^c Ã— log n) where c = log_b(a)
        Then T(n) = O(n^c Ã— log n)

Case 3: If f(n) = O(n^c) where c > log_b(a)
        Then T(n) = O(f(n))
```

**Examples:**
```
1. T(n) = 2T(n/2) + n
   a=2, b=2, f(n)=n
   log_b(a) = logâ‚‚(2) = 1
   f(n) = nÂ¹ = n^(logâ‚‚ 2)
   Case 2: T(n) = O(n log n)  [Merge Sort]

2. T(n) = T(n/2) + 1
   a=1, b=2, f(n)=1
   log_b(a) = logâ‚‚(1) = 0
   f(n) = nâ° = 1
   Case 2: T(n) = O(log n)  [Binary Search]

3. T(n) = 2T(n/2) + nÂ²
   a=2, b=2, f(n)=nÂ²
   log_b(a) = 1, but f(n)=nÂ² (bigger!)
   Case 3: T(n) = O(nÂ²)
```

---

## Basic Probability and Combinatorics

### Counting Principles

#### 1. Addition Rule
**If** you can do A in m ways **OR** B in n ways (not both):  
**Then** total ways = m + n

```
Example: Travel from A to B
- 3 bus routes OR
- 2 train routes
Total: 3 + 2 = 5 ways
```

#### 2. Multiplication Rule
**If** you do A in m ways **AND THEN** B in n ways:  
**Then** total ways = m Ã— n

```
Example: Password with 2 digits
- First digit: 10 choices (0-9)
- Second digit: 10 choices (0-9)
Total: 10 Ã— 10 = 100 passwords
```

### Permutations

**Definition:** Arrangements where order matters

**Formula:** P(n, r) = n!/(n-r)!

```
Arranging r items from n items:

Example: Choose 2 positions from 5 people
P(5, 2) = 5!/(5-2)! = 5!/3! = 5 Ã— 4 = 20

[A,B], [A,C], [A,D], [A,E]
[B,A], [B,C], [B,D], [B,E]
[C,A], [C,B], [C,D], [C,E]
[D,A], [D,B], [D,C], [D,E]
[E,A], [E,B], [E,C], [E,D]
Total: 20 arrangements
```

**DSA Application:**
```python
def permute(arr):
    if len(arr) <= 1:
        return [arr]
    result = []
    for i in range(len(arr)):
        rest = arr[:i] + arr[i+1:]
        for p in permute(rest):
            result.append([arr[i]] + p)
    return result

# For n elements: n! permutations
# Time: O(n!)
```

### Combinations

**Definition:** Selections where order doesn't matter

**Formula:** C(n, r) = n! / (r!(n-r)!)

```
Choosing r items from n items:

Example: Choose 2 from 5 people
C(5, 2) = 5! / (2! Ã— 3!) = 10

{A,B}, {A,C}, {A,D}, {A,E}
{B,C}, {B,D}, {B,E}
{C,D}, {C,E}
{D,E}
Total: 10 combinations

Note: {A,B} = {B,A} (same combination)
```

**DSA Application:**
```python
def combine(n, k):
    result = []
    
    def backtrack(start, path):
        if len(path) == k:
            result.append(path[:])
            return
        
        for i in range(start, n+1):
            path.append(i)
            backtrack(i+1, path)
            path.pop()
    
    backtrack(1, [])
    return result

# Generate C(n, k) combinations
```

### Probability Basics

**Probability:** P(Event) = Favorable outcomes / Total outcomes

```
Example: Rolling a die

P(getting 6) = 1/6
P(getting even) = 3/6 = 1/2
P(getting < 5) = 4/6 = 2/3
```

**DSA Application (Randomized Algorithms):**
```python
import random

def quick_sort_randomized(arr):
    if len(arr) <= 1:
        return arr
    
    # Random pivot selection
    pivot_idx = random.randint(0, len(arr)-1)
    pivot = arr[pivot_idx]
    
    # Partition
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quick_sort_randomized(left) + middle + \
           quick_sort_randomized(right)

# Expected time: O(n log n)
# Worst case: O(nÂ²) but probability is very low
```

---

## ğŸ¯ Practice: 8 Mathematical Problems

### Problem 1: Sum Formula
**Question:** What is 1 + 2 + 3 + ... + 1000?  
**Hint:** Use arithmetic series formula

<details>
<summary>Solution</summary>
Sum = n(n+1)/2 = 1000(1001)/2 = 500,500
</details>

---

### Problem 2: Powers of 2
**Question:** How many times can you divide 1024 by 2 until you reach 1?  
**Hint:** Think logarithms

<details>
<summary>Solution</summary>
logâ‚‚(1024) = 10 (because 2Â¹â° = 1024)
Answer: 10 divisions
</details>

---

### Problem 3: Nested Loop Count
**Question:** How many times does the inner statement execute?
```python
for i in range(n):
    for j in range(i):
        print("Hello")
```
**Hint:** Sum from 0 to n-1

<details>
<summary>Solution</summary>
0 + 1 + 2 + ... + (n-1) = (n-1)n/2 = O(nÂ²)
</details>

---

### Problem 4: Binary Tree Nodes
**Question:** A complete binary tree has height h. How many nodes total?  
**Hint:** Geometric series

<details>
<summary>Solution</summary>
1 + 2 + 4 + ... + 2Ê° = 2^(h+1) - 1 nodes
</details>

---

### Problem 5: Permutations
**Question:** How many ways can you arrange 5 books on a shelf?

<details>
<summary>Solution</summary>
5! = 5 Ã— 4 Ã— 3 Ã— 2 Ã— 1 = 120 ways
</details>

---

### Problem 6: Combinations
**Question:** Choose 3 students from a class of 10. How many ways?  
**Hint:** C(n, r) formula

<details>
<summary>Solution</summary>
C(10, 3) = 10!/(3! Ã— 7!) = (10 Ã— 9 Ã— 8)/(3 Ã— 2 Ã— 1) = 120 ways
</details>

---

### Problem 7: Recurrence
**Question:** Solve T(n) = T(n-1) + 1, T(1) = 1  
**Hint:** Expand the recurrence

<details>
<summary>Solution</summary>
T(n) = T(n-1) + 1  
     = T(n-2) + 1 + 1  
     = T(1) + (n-1)  
     = 1 + n - 1 = n  
Answer: O(n)
</details>

---

### Problem 8: Probability
**Question:** You have array [1,2,3,4,5]. If you pick 2 random distinct elements, what's probability their sum is even?

<details>
<summary>Solution</summary>
Sum is even if: both odd OR both even  
Odd numbers: {1, 3, 5} - choose 2: C(3,2) = 3  
Even numbers: {2, 4} - choose 2: C(2,2) = 1  
Total: 3 + 1 = 4  
All possible pairs: C(5,2) = 10  
Probability: 4/10 = 2/5 = 0.4
</details>

---

## ğŸ“Š Module 1 Summary

### Key Concepts Mastered

âœ… **Data Structures & Algorithms fundamentals**  
âœ… **Problem-solving framework (4 steps)**  
âœ… **Time complexity (Big O notation)**  
âœ… **Space complexity analysis**  
âœ… **Common complexity classes**  
âœ… **Mathematical foundations**  
âœ… **Recurrence relations**  
âœ… **Probability & Combinatorics basics**

### Complexity Cheat Sheet

```
Constant:      O(1)        â†’ Array access, hash lookup
Logarithmic:   O(log n)    â†’ Binary search, balanced tree
Linear:        O(n)        â†’ Single loop, linear search
Linearithmic:  O(n log n)  â†’ Merge sort, heap sort
Quadratic:     O(nÂ²)       â†’ Nested loops, bubble sort
Cubic:         O(nÂ³)       â†’ Triple nested loops
Exponential:   O(2â¿)       â†’ Recursive fibonacci
Factorial:     O(n!)       â†’ Permutations
```

### Next Steps

**Before moving to Module 2:**
1. âœ“ Complete all 23 practice problems
2. âœ“ Review any concepts you found difficult
3. âœ“ Practice explaining complexities out loud
4. âœ“ Understand, don't just memorize!

**Coming up in Module 2:**
- Arrays in depth
- String manipulation
- Two-pointer techniques
- Sliding window pattern

---

## ğŸ’¡ Pro Tips for Success

1. **Draw it out:** Visualize algorithms on paper
2. **Walk through examples:** Trace code with small inputs
3. **Practice regularly:** 30 min daily > 3 hours weekly
4. **Explain to others:** Teaching solidifies understanding
5. **Don't rush:** Understanding > Speed

---

**Remember:** Every expert was once a beginner. Take your time with these foundations - they're the bedrock of everything else!

**Happy Learning! ğŸš€**

---

*Module created with â¤ï¸ for aspiring software engineers*  
*Questions? Review this module again or practice more problems!*